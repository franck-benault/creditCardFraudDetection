{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c2babf-89bf-461d-8c82-e8dde7974531",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Kaggle\n",
    "#date=''\n",
    "\n",
    "#For WL data\n",
    "source='WL'\n",
    "date='20241118'\n",
    "\n",
    "saveImage=False\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99510ba6-2f13-42f0-a598-c6beaa7207c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "fpath = os.path.join('..//scripts')\n",
    "sys.path.append(fpath)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#loading internal scripts\n",
    "import frauddetection as fd\n",
    "import sourcedata as sd\n",
    "import dataimport as di\n",
    "reload(fd)\n",
    "reload(sd)\n",
    "reload(di)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6b87d8-ae8a-4e9f-a9ec-e87caeddcaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfTrx = pd.read_csv('../data/cleaned/'+source+'export'+date+'.csv')\n",
    "dfTrx.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2f9dfd-a7f0-41ab-ad05-8e3a6522d8fc",
   "metadata": {},
   "source": [
    "# Test with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b61971-3d64-4b63-9a81-a4c0a767eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "then= datetime.now()\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "\n",
    "modelClf = xgb.XGBClassifier()\n",
    "modelClf.fit(x_train, y_train)\n",
    "predsTrain = modelClf.predict(x_train)\n",
    "predsTest = modelClf.predict(x_test)\n",
    "\n",
    "now = datetime.now()\n",
    "duration= now - then\n",
    "duration_in_s = duration.total_seconds()\n",
    "print(\"Duration \",duration_in_s)\n",
    "\n",
    "fd.print_scores(y_train, predsTrain,'f1', False)\n",
    "fd.print_scores(y_test, predsTest,'f1')\n",
    "fd.show_importance(modelClf, predictors)\n",
    "fd.show_confusion_matrix(y_test, predsTest)\n",
    "\n",
    "# result \n",
    "#train f1 score: 0.1205,mcc score: 0.2288,roc auc score: 0.5325\n",
    "#test f1 score: 0.0258,mcc score: 0.0633, roc auc score: 0.5067"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3841dd-02bc-4b61-b478-b430208fe9a6",
   "metadata": {},
   "source": [
    "# Scaling choice\n",
    "with xgboost the scaling has no influence ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7ed20-fbb5-4e47-b74d-3efa61226bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "# scaling choice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "parameters={}\n",
    "#parameters['max_iter']=1000\n",
    "\n",
    "modelClf = xgb.XGBClassifier()\n",
    "duration_in_s,f1Train,f1Test, scaler = fd.processModel(modelClf,dfTrx, predictors,[], parameters, scaler=None)\n",
    "scalers = fd.getScalers()\n",
    "for key in scalers:\n",
    "    print(key)\n",
    "    scaler=scalers.get(key)\n",
    "    modelClf = xgb.XGBClassifier()\n",
    "    duration_in_s,f1Train,f1Test, scaler = fd.processModel(modelClf,dfTrx, predictors, [],parameters,scaler=scaler)\n",
    "\n",
    "# scaler has no adding value for the result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cd093-9a95-4d4f-b502-3617ef49b497",
   "metadata": {},
   "source": [
    "# Hyperparameters choice\n",
    "starting point\n",
    "n_estimators=50,learning_rate=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab116a6-aabc-4877-b4bb-2ae5d03bf55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "modelClf = xgb.XGBClassifier()\n",
    "# starting point n_estimators=100,  max_depth=7 \n",
    "dic_param={\n",
    "    'n_estimators':[50,100,200],\n",
    "    'max_depth':[3,5,7],\n",
    "    'learning_rate':[0.01,0.05,0.1],\n",
    "    'subsample':[0.8,1.0],\n",
    "    'colsample_bytree':[0.8,1.0]\n",
    "}\n",
    "res=fd.hyperparameterSelectionRandomizedSearchCV(modelClf, dic_param, 'f1', dfTrx, predictors, [], None)\n",
    "print(res)\n",
    "# result (22/01/2025)\n",
    "# result {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 1.0} scoref1 0.013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465ddde-31dd-47f1-beb6-80ebad082f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "modelClf = xgb.XGBClassifier()\n",
    "\n",
    "dic_param={\n",
    "    'n_estimators':[400,500,600],\n",
    "    'max_depth':[5,6,7],\n",
    "    'learning_rate':[0.4,0.5,0.6],\n",
    "    'subsample':[0.8,1.0],\n",
    "    'colsa,.3mple_bytree':[0.8,1.0]\n",
    "}\n",
    "res=fd.hyperparameterSelectionGridSearchCV(modelClf, dic_param, 'f1', dfTrx, predictors, [], None)\n",
    "print(res)\n",
    "\n",
    "# 23/01/2025\n",
    "#dic 'n_estimators':[100,200,300],'max_depth':[2,3,4],'learning_rate':[0.01,0.1,0.2],'subsample':[0.8,1.0],'colsample_bytree':[0.8,1.0]\n",
    "# {'colsample_bytree': 1.0, 'learning_rate': 0.2, 'max_depth': 4, 'n_estimators': 300, 'subsample': 0.8} scoref1 0.0829\n",
    "#dic 'n_estimators':[200,300,400],'max_depth':[3,4,5],'learning_rate':[0.1,0.2,0.3],'subsample':[0.8,1.0],'colsample_bytree':[0.8,1.0]\n",
    "# {'colsample_bytree': 1.0, 'learning_rate': 0.3, 'max_depth': 5, 'n_estimators': 300, 'subsample': 0.8} scoref1 0.1424\n",
    "# dic_param={'n_estimators':[200,300,400],'max_depth':[4,5,6],'learning_rate':[0.2,0.3,0.4],'subsample':[0.8,1.0],'colsample_bytree':[0.8,1.0]\n",
    "#{'colsample_bytree': 0.8, 'learning_rate': 0.4, 'max_depth': 6, 'n_estimators': 300, 'subsample': 0.8} scoref1 0.1964\n",
    "#dic_param={'n_estimators':[200,300,400],'max_depth':[4,5,6],'learning_rate':[0.3,0.4,0.5],'subsample':[0.8,1.0],'colsample_bytree':[0.8,1.0]\n",
    "#{'colsample_bytree': 1.0, 'learning_rate': 0.5, 'max_depth': 6, 'n_estimators': 400, 'subsample': 0.8}sco ref1 0.2498\n",
    "# dic_param={'n_estimators':[300,400,500],'max_depth':[5,6,7],'learning_rate':[0.4,0.5,0.6],'subsample':[0.8,1.0],'colsample_bytree':[0.8,1.0]\n",
    "#{'colsample_bytree': 1.0, 'learning_rate': 0.5, 'max_depth': 6, 'n_estimators': 500, 'subsample': 0.8} scoref1 0.2767\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fcab9d-be8f-491f-a9af-c40daf1dffbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "then= datetime.now()\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "parameters= {'colsample_bytree': 1.0, 'learning_rate': 0.4, 'max_depth': 6, 'n_estimators': 500, 'subsample': 0.8}\n",
    "\n",
    "modelClf = xgb.XGBClassifier()\n",
    "modelClf.set_params(**parameters)\n",
    "modelClf.fit(x_train, y_train)\n",
    "predsTrain = modelClf.predict(x_train)\n",
    "predsTest = modelClf.predict(x_test)\n",
    "\n",
    "now = datetime.now()\n",
    "duration= now - then\n",
    "duration_in_s = duration.total_seconds()\n",
    "print(\"Duration \",duration_in_s)\n",
    "\n",
    "fd.print_scores(y_train, predsTrain,'f1', False)\n",
    "fd.print_scores(y_test, predsTest,'f1')\n",
    "fd.show_importance(modelClf, predictors)\n",
    "fd.show_confusion_matrix(y_test, predsTest)\n",
    "\n",
    "## result  (23/01/2025)\n",
    "#test f1 score: 0.0717, mcc score: 0.1136, roc auc score: 0.5201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b184a2-610a-49da-9f46-6ee26af14e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fd.getAllFiles()\n",
    "\n",
    "range = []\n",
    "results = []\n",
    "loop =0\n",
    "for file in files:\n",
    "    loop=loop+1\n",
    "    range.append(loop)\n",
    "    print(file)\n",
    "  \n",
    "    dfTrx = pd.read_csv('../data/cleaned/'+source+file)\n",
    "    predictors = fd.getPredictors(dfTrx)\n",
    "\n",
    "    preds = modelClf.predict(dfTrx[predictors])\n",
    "\n",
    "    result= fd.print_scores(dfTrx['Class'], preds,'f1', True)\n",
    "    fd.show_confusion_matrix(dfTrx['Class'], preds)\n",
    "    results.append(result)\n",
    "\n",
    "fd.plt_train_test(range, results)\n",
    "\n",
    "#test result (22/01/2025)\n",
    "# d1 f1= 0.1293\n",
    "# d2 f1= 0.0169\n",
    "# d3 f1= 0.0270\n",
    "# d7 f1= 0.5730"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927a5573-d010-4a61-9c75-1bdefebe28d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
