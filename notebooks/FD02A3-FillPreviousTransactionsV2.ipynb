{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9f612e-b4da-497f-b54d-27c485b2f564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "fpath = os.path.join('..//scripts')\n",
    "sys.path.append(fpath)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#loading internal scripts\n",
    "import frauddetection as fd\n",
    "import sourcedata as sd\n",
    "import countrymanagement as cm\n",
    "import mccmanagement as mccm\n",
    "reload(fd)\n",
    "reload(sd)\n",
    "reload(cm)\n",
    "reload(mccm)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace7ce9-638b-43f5-bb04-cc5d425ef5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#For Kaggle\n",
    "#date=''\n",
    "\n",
    "#For WL data\n",
    "date='20241118'\n",
    "source='WL'\n",
    "\n",
    "saveImg=False\n",
    "\n",
    "print('done')\n",
    "\n",
    "dfTrxSaved = pd.read_csv('../data/cleaned/'+source+'export'+date+'.csv')\n",
    "dfTrxSaved.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322949db-e53e-471c-87db-7872a5be9233",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTrxSaved['term_mcc'] = dfTrxSaved['term_mcc'].astype(str)\n",
    "dfTrxSaved['word']=dfTrxSaved['term_country']+dfTrxSaved['term_mcc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a4a4e-9fef-4cbc-8fdf-e1e860cfe317",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df = dfTrxSaved.sort_values(by=['card_pan_id','trx_date_time'])\n",
    "sorted_df=sorted_df.drop(columns=['mcd_fraud_score','vaa_score',\n",
    "                                 'trx_amount_log10','card_brand_MCD',\t'card_brand_VIS','country_group_BELGIUM','country_group_EUROPE',\n",
    "                                 'clusterCardHolder_cluster0',\t'clusterCardHolder_cluster1',\t'clusterCardHolder_cluster2',\t'clusterCardHolder_cluster3',\t\n",
    "                                 'clusterCardHolder_cluster4',\t'clusterMerchant_M0',\t'clusterMerchant_M1','clusterMerchant_M2','clusterMerchant_M3',\n",
    "                                 'clusterMerchant_UNKNOWN',\n",
    "                                  'country_group_WORLD','mcc_group_CLOTHING_STORES',\t\n",
    "                                  'mcc_group_GOUVERNEMENT_SERVICES','mcc_group_OTHER','mcc_group_PROFESSIONAL_SERVICES',\t\n",
    "                                  'mcc_group_RETAIL_OUTLET_SERVICES','mcc_group_UTILITY_SERVICES','mcc_group_ATM',\t\n",
    "                                  'trx_reversal_FULL_REVERSAL',\t'trx_reversal_NO_RESERSAL',\t\n",
    "                                  'trx_reversal_PARTIAL_REVERSAL','clusterCardHolder_UNKNOWN'\n",
    "                                 ])\n",
    "\n",
    "\n",
    "\n",
    "sorted_df['card_pan_id1'] = sorted_df['card_pan_id'].shift(-1)\n",
    "#sorted_df['term_mcc1']= sorted_df['term_mcc'].shift(-1) if sorted_df['card_pan_id1'] == sorted_df['card_pan_id'] else 'XXXX'\n",
    "sorted_df['word1'] = sorted_df['word'].shift(-1)\n",
    "sorted_df['ecom1'] = sorted_df['ecom'].shift(-1)\n",
    "sorted_df['db_uuid1'] = sorted_df['db_uuid'].shift(-1)\n",
    "sorted_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54debcfa-5182-4602-91ed-187b760a9b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_df1=sorted_df[(sorted_df['card_pan_id']==sorted_df['card_pan_id1'])]\n",
    "sorted_df0=sorted_df[(sorted_df['card_pan_id']!=sorted_df['card_pan_id1'])]\n",
    "\n",
    "print(sorted_df.shape)\n",
    "print(sorted_df0.shape)\n",
    "print(sorted_df1.shape)\n",
    "\n",
    "print(sorted_df.Class.value_counts(normalize=True))\n",
    "print(sorted_df0.Class.value_counts(normalize=True))\n",
    "print(sorted_df1.Class.value_counts(normalize=True))\n",
    "\n",
    "\n",
    "#sorted_df4.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2c977-06e1-4054-8c60-7e36f4a69a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "dfTrxSaved['previous_trx']=0\n",
    "\n",
    "sorted_dfTemp=sorted_df[(sorted_df['card_pan_id']==sorted_df['card_pan_id1'])]\n",
    "dfTrxSaved['previous_trx']=np.where(sorted_df.index.isin(sorted_dfTemp.index),1,dfTrxSaved['previous_trx'])\n",
    "\n",
    "dfTrxSaved['card_pan_id1']=sorted_df['card_pan_id1']\n",
    "dfTrxSaved['word1'] = sorted_df['word1']\n",
    "dfTrxSaved['ecom']=sorted_df['ecom']\n",
    "dfTrxSaved['ecom1']=sorted_df['ecom1']\n",
    "dfTrxSaved['db_uuid1']=sorted_df['db_uuid1']\n",
    "\n",
    "print(dfTrxSaved['previous_trx'].value_counts())\n",
    "dfTrxSaved.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0095282-0428-4292-9a85-c4fc1601fed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1=dfTrxSaved[(dfTrxSaved['card_pan_id']==dfTrxSaved['card_pan_id1'])&(dfTrxSaved['word']!=dfTrxSaved['word1'])]\n",
    "temp2=dfTrxSaved[(dfTrxSaved['card_pan_id']==dfTrxSaved['card_pan_id1'])&(dfTrxSaved['word']==dfTrxSaved['word1'])]\n",
    "\n",
    "print(temp1.shape)\n",
    "print(temp2.shape)\n",
    "temp2[['word','word1']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1c262b-da47-4543-9874-35e6d947bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2=dfTrxSaved[(dfTrxSaved['card_pan_id']==dfTrxSaved['card_pan_id1'])&(dfTrxSaved['word']!=dfTrxSaved['word1'])]\n",
    "temp2[['trx_date_time','card_pan_id','card_pan_id1','word','word1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c28689a-82be-4f48-adb2-0ea0dc59c8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "f=open(\"../data/processed/countrymcc.txt\",\"w+\") # file name and mode\n",
    "text=''\n",
    "for index,row in temp2.iterrows():\n",
    "    if((index % 5000)==0):\n",
    "        print(\"\",index)\n",
    "    f.write(row['word1']+\" \"+row['word']+'.\\n')\n",
    "    text=text+row['word1']+\" \"+row['word']+'.\\n'\n",
    "f.close()\n",
    "print('done ',index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efa07fa-c676-4eeb-b117-62d3b40c0b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "token=word_tokenize(text)\n",
    "tokenClean= [i for i in token if i is not '.']\n",
    "freq= nltk.FreqDist(tokenClean)\n",
    "freq.plot(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d90fef-9945-4880-8baa-40add6213839",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    " \n",
    "warnings.filterwarnings(action='ignore')\n",
    "\n",
    "data = []\n",
    " \n",
    "# iterate through each sentence in the file\n",
    "for i in sent_tokenize(text):\n",
    "    temp = []\n",
    " \n",
    "    # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j)\n",
    " \n",
    "    data.append(temp)\n",
    "\n",
    "model = Word2Vec(data,min_count=1,window=2,max_vocab_size=2000000)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa880536-f649-484e-8e96-3ac2fc0b6c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_not_present(wordT):\n",
    "    if (wordT in model.wv.key_to_index):\n",
    "        return wordT\n",
    "    else:\n",
    "        print(wordT)\n",
    "        return 'BEL5411'\n",
    "\n",
    "\n",
    "dfTrxSaved['word'] = dfTrxSaved['word'].apply(word_not_present)\n",
    "dfTrxSaved['word1'] = dfTrxSaved['word1'].apply(word_not_present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b2b99d-3bba-4786-a55b-c2a0a950ff80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dfTrxSaved['distancePrevTrx']= \n",
    "#model.wv.similarity(dfTrxSaved['word'], dfTrxSaved['word1'])\n",
    "print(dfTrxSaved[['word','word1']].head(128))\n",
    "dfTrxSaved['distancePrevTrx']= dfTrxSaved[['word1','word']].apply(lambda x: model.wv.similarity(x[0],x[1]), axis=1)\n",
    "\n",
    "#dfTemp=dfTrxSaved[(dfTrxSaved['previous_trx']==1)\n",
    "\n",
    "\n",
    "#dfTrxSaved['distancePrevTrx']=np.where(sorted_df.index.isin(dfTemp.index),1,model.wv.similarity(dfTrxSaved['word'], dfTrxSaved['word1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f921155-6ff5-4cc1-adf3-990293a9ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<1.0)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.9)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.8)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.7)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.6)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.5)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.4)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.3)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.2)].shape)\n",
    "print(dfTrxSaved['distancePrevTrx'][(dfTrxSaved['distancePrevTrx']<0.1)].shape)\n",
    "\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']==1.0)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<1.0)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.9)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.8)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.7)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.6)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.5)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.4)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.3)].value_counts(normalize=True))\n",
    "print(dfTrxSaved['Class'][(dfTrxSaved['distancePrevTrx']<0.2)].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f239be-a4ce-4341-872b-859653a8d003",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max = 11\n",
    "\n",
    "print('distancePrevTrx')\n",
    "for bins in np.arange(2,max,1):\n",
    "    dfTrxSaved['distancePrevTrxBin']=pd.cut(dfTrxSaved['distancePrevTrx'], bins=bins)\n",
    "    print(f'IV trx_local_amt_val bins={bins} {fd.calc_iv(dfTrxSaved,'distancePrevTrxBin','Class',pr=0)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0e3c34-07d7-4473-847e-58f090891e09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
