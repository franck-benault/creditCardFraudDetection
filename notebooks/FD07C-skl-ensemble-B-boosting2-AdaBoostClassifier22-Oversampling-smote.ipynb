{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e922f-84cb-4556-a6d9-dea7ce222301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Kaggle\n",
    "#date=''\n",
    "\n",
    "#For WL data\n",
    "source='WL'\n",
    "date='20241118'\n",
    "\n",
    "saveImage=False\n",
    "\n",
    "packageName='07-sklearn.ensemble.b-boosting'\n",
    "classifierName='5-AdaBoostClassifier'\n",
    "extraParameterName='22-SmoteOverSampling'\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53106652-5d8c-4b52-8d38-a65e992b1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "fpath = os.path.join('..//scripts')\n",
    "sys.path.append(fpath)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#loading internal scripts\n",
    "import frauddetection as fd\n",
    "import sourcedata as sd\n",
    "import dataimport as di\n",
    "import result as resultMd\n",
    "import sampling as sp\n",
    "reload(fd)\n",
    "reload(sd)\n",
    "reload(di)\n",
    "reload(resultMd)\n",
    "reload(sp)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d98283a5-10ec-46c7-86cf-26c70c3ae7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "\n",
    "estimator__max_depthFound=1\n",
    "# learning too low makes the process very slow\n",
    "learning_rateFound=0.1\n",
    "n_estimatorsFound=850\n",
    "\n",
    "resultMd.update_hyperparameter_config_result(packageName,classifierName,extraParameterName,estimator__max_depthFound,n_estimatorsFound)\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f119e-bb6e-4236-88de-526cb617e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfTrx0 = pd.read_csv('../data/cleaned/'+source+'export'+date+'.csv')\n",
    "predictors = fd.getPredictors(dfTrx0)\n",
    "dfTrx=fd.getStandardScaledData('export'+date+'.csv',source,predictors)\n",
    "dfTrx.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd41b98-e54a-464f-8429-06135db22c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "predictors = fd.getPredictors(dfTrx0)\n",
    "TEST_SIZE = 0.20 # test size using_train_test_split\n",
    "RANDOM_STATE = 0\n",
    "x_train0, x_test, y_train0, y_test = train_test_split(dfTrx[predictors], dfTrx['Class'], test_size = TEST_SIZE, \n",
    "                                                        stratify= dfTrx['Class'],\n",
    "                                                        random_state = RANDOM_STATE)\n",
    "\n",
    "x_train, y_train = sp.smoteOverSampling(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f97321e-c728-4570-82f1-2991bbadf1bf",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c240e40a-d919-4c27-96d0-b9cc920236bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "modelClf = AdaBoostClassifier(random_state=42)\n",
    "dic_param={\n",
    "    'estimator': [DecisionTreeClassifier()],\n",
    "    'estimator__max_depth':randint(5,7),\n",
    "    'n_estimators': randint(45,60),\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "res=fd.hyperparameterSelectionRandomizedSearchCVSampling(modelClf, dic_param, 'f1', x_train, y_train,iter=3)\n",
    "\n",
    "\n",
    "print(res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbce2a8-4478-4f86-a525-511298da766a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%script false\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "modelClf = AdaBoostClassifier(random_state=42)\n",
    "\n",
    " \n",
    "dic_param={\n",
    "     'estimator': [DecisionTreeClassifier()],\n",
    "    'estimator__max_depth':[1],\n",
    "    'n_estimators':[950,1000],\n",
    "    'learning_rate':[0.1]\n",
    "}\n",
    "\n",
    "res=fd.hyperparameterSelectionGridSearchCVSampling(modelClf, dic_param, 'f1', x_train, y_train)\n",
    "print(res)\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 300}\n",
    "#0.18143577468756722\n",
    "#scoref1 0.19466327827191868\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 400}\n",
    "#0.20356590745376701\n",
    "#scoref1 0.2236118059029515\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 500}\n",
    "#0.20648242324167213\n",
    "#scoref1 0.21861741951584726\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 600}\n",
    "#0.23999649738454054\n",
    "#scoref1 0.24828263002944062\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 700}\n",
    "#0.24557102536085562\n",
    "#scoref1 0.2644989080320311\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 750}\n",
    "#0.2452300947649264\n",
    "#scoref1 0.26034063260340634\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 800}\n",
    "#0.2573530014752987\n",
    "#scoref1 0.2770997846374731\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 850}\n",
    "#0.2535756159534257\n",
    "#scoref1 0.28296901273120345\n",
    "\n",
    "#    'n_estimators':[850,900],\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 900}\n",
    "#0.27484178493266553\n",
    "#scoref1 0.3009685802031656\n",
    "\n",
    "#{'estimator': DecisionTreeClassifier(), 'estimator__max_depth': 1, 'learning_rate': 0.1, 'n_estimators': 950}\n",
    "#0.2783865149619385\n",
    "#scoref1 0.30151946818613484\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae1be4-a998-4ad9-8cd0-131e5ce3af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "then= datetime.now()\n",
    "\n",
    "\n",
    "\n",
    "modelClf = AdaBoostClassifier(random_state=42)\n",
    "parameters={'learning_rate': learning_rateFound, 'n_estimators':n_estimatorsFound, 'estimator':DecisionTreeClassifier(),\n",
    "           'estimator__max_depth':estimator__max_depthFound}\n",
    "modelClf.set_params(**parameters)\n",
    "\n",
    "modelClf.fit(x_train, y_train)\n",
    "predsTrain = modelClf.predict(x_train)\n",
    "predsTest = modelClf.predict(x_test)\n",
    "\n",
    "predsTrain = modelClf.predict(x_train)\n",
    "predsTest = modelClf.predict(x_test)\n",
    "\n",
    "f1Train=fd.print_scores(y_train, predsTrain,'f1', False)\n",
    "f1Test=fd.print_scores(y_test, predsTest,'f1')\n",
    "fd.show_importance(modelClf, predictors)\n",
    "fd.show_confusion_matrix(y_test, predsTest)\n",
    "fd.show_prediction_graph(modelClf, x_test,y_test)\n",
    "\n",
    "diffF1=f1Train-f1Test\n",
    "print(\"diffF1\",diffF1)\n",
    "\n",
    "tmp = pd.DataFrame({'Feature': predictors, 'Feature importance': modelClf.feature_importances_})\n",
    "val=tmp[(tmp['Feature']=='amountBin')]['Feature importance']\n",
    "amountImportance =val.values[0]\n",
    "print(\"amount importance\",amountImportance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d9491-f833-4537-9a65-076404bde78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fd.getAllFiles()\n",
    "predictors = fd.getPredictors(dfTrx0)\n",
    "\n",
    "range = []\n",
    "f1s = []\n",
    "rocs = []\n",
    "loop =0\n",
    "for file in files:\n",
    "    loop=loop+1\n",
    "    range.append(loop)\n",
    "    print(file)\n",
    "  \n",
    "    dfTrx=fd.getStandardScaledData(file,source,predictors)\n",
    "    preds = modelClf.predict(dfTrx[predictors])\n",
    "\n",
    "    f1,mcc,roc= fd.print_scores(dfTrx['Class'], preds,'All', True)\n",
    "    #fd.show_importance(modelClf,predictors)\n",
    "    fd.show_confusion_matrix(dfTrx['Class'], preds)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "fd.plt_train_test(range, f1s)\n",
    "resultMd.update_performance_nextdays_result(packageName,classifierName,extraParameterName, f1s[0],f1s[1],f1s[2],f1s[3],rocs[0],rocs[1],rocs[2],rocs[3],diffF1,amountImportance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bd233f-abc8-4ccd-b14a-2bb02d2a3fde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
