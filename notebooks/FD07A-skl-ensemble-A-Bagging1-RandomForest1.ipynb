{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d754aef-0c61-4f95-84c0-b8330c56d67b",
   "metadata": {},
   "source": [
    "# Random forest classifier introduction\n",
    "* this is  a ensemble bagging method coming from sklearn\n",
    "* there is risk of overfitting \n",
    "* to avoid overfitting the max_depth must not be bigger than 15\n",
    "* Because it is a bagging method good result is not expected for imbalanced data\n",
    "* Does not need scaling or normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9e922f-84cb-4556-a6d9-dea7ce222301",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Kaggle\n",
    "#date=''\n",
    "\n",
    "#For WL data\n",
    "source='WL'\n",
    "date='20241118'\n",
    "\n",
    "saveImage=False\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53106652-5d8c-4b52-8d38-a65e992b1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from importlib import reload\n",
    "fpath = os.path.join('..//scripts')\n",
    "sys.path.append(fpath)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#loading internal scripts\n",
    "import frauddetection as fd\n",
    "import sourcedata as sd\n",
    "import dataimport as di\n",
    "import result as resultMd\n",
    "reload(fd)\n",
    "reload(sd)\n",
    "reload(di)\n",
    "reload(resultMd)\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815caabe-4406-48c6-871b-6e926c85d9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters Results\n",
    "\n",
    "n_estimatorsFound=60\n",
    "max_depthFound=23\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6f119e-bb6e-4236-88de-526cb617e9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dfTrx = pd.read_csv('../data/cleaned/'+source+'export'+date+'.csv')\n",
    "dfTrx.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50b4b4b-05dc-4db9-b6f3-26133ac817e6",
   "metadata": {},
   "source": [
    "# Test with default hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c75f3-9d3a-45dd-a778-abbe0e12efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "then= datetime.now()\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "\n",
    "modelClf = RandomForestClassifier(random_state=42)\n",
    "modelClf.fit(x_train, y_train)\n",
    "predsTrain = modelClf.predict(x_train)\n",
    "predsTest = modelClf.predict(x_test)\n",
    "\n",
    "now = datetime.now()\n",
    "duration= now - then\n",
    "duration_in_s = duration.total_seconds()\n",
    "print(\"Duration \",duration_in_s)\n",
    "resultMd.update_time_response_result('07-sklearn.ensemble.a-bagging','RandomForest','1-Default', duration_in_s)\n",
    "f1,mcc,roc=fd.print_scores(y_test, predsTest,'all')\n",
    "resultMd.update_performance_test_result('07-sklearn.ensemble-a-bagging','RandomForest','1-Default', f1,mcc,roc)\n",
    "\n",
    "fd.print_scores(y_train, predsTrain,'f1', False)\n",
    "fd.print_scores(y_test, predsTest,'f1')\n",
    "fd.show_importance(modelClf, predictors)\n",
    "fd.show_confusion_matrix(y_test, predsTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7da6108-76d2-4cbb-b2b3-2b99565fe999",
   "metadata": {},
   "source": [
    "# Default parameters conclusion\n",
    "Overfitting probably due to the default parameter max_depth=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b337d68c-eeb6-4b5b-85ad-213f2d9adf88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, balanced_accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "train_f1s=[]\n",
    "test_f1s=[]\n",
    "range= []\n",
    "# too low max_depth -> no result\n",
    "for max_depth in np.arange(8,21,1):\n",
    "    print('max_depth',max_depth)\n",
    "    # Instantiate model and k-fold\n",
    "    modelClf = RandomForestClassifier(random_state=42, max_depth=max_depth)\n",
    "    modelClf.fit(x_train, y_train)\n",
    "    train_preds = modelClf.predict(x_train)\n",
    "    train_f1 = f1_score(y_train,train_preds)\n",
    "\n",
    "    test_preds = modelClf.predict(x_test)\n",
    "    test_f1 = f1_score(y_test,test_preds)\n",
    "    #fd.show_confusion_matrix(y_train, train_preds)\n",
    "\n",
    "    print(\"train_f1\", train_f1)\n",
    "    print(\"test_f1\", test_f1)\n",
    "    print(\"dif\", train_f1-test_f1)\n",
    "    train_f1s.append(train_f1)\n",
    "    test_f1s.append(test_f1)\n",
    "    range.append(max_depth)\n",
    "    print('-----------------------')\n",
    "\n",
    "fd.plt_train_test(range, train_f1s, \"train\", test_f1s,\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4b7ea8-f3e7-41a6-bf66-db9a960eec48",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, balanced_accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "train_f1s=[]\n",
    "test_f1s =[]\n",
    "range= []\n",
    "# too low max_depth -> no result\n",
    "for n_estimators in np.arange(20,201,20):\n",
    "    print('n_estimators',n_estimators)\n",
    "    # Instantiate model and k-fold\n",
    "    modelClf = RandomForestClassifier(random_state=42, max_depth=15, n_estimators=n_estimators)\n",
    "    modelClf.fit(x_train, y_train)\n",
    "    train_preds = modelClf.predict(x_train)\n",
    "    train_f1 = f1_score(y_train,train_preds)\n",
    "\n",
    "    test_preds = modelClf.predict(x_test)\n",
    "    test_f1 = f1_score(y_test,test_preds)\n",
    "    #fd.show_confusion_matrix(y_train, train_preds)\n",
    "\n",
    "    print(\"train_f1\", train_f1)\n",
    "    print(\"test_f1\", test_f1)\n",
    "    print(\"dif\", train_f1-test_f1)\n",
    "    train_f1s.append(train_f1)\n",
    "    test_f1s.append(test_f1)\n",
    "    range.append(n_estimators)\n",
    "    print('-----------------------')\n",
    "\n",
    "fd.plt_train_test(range, train_f1s, \"train\", test_f1s,\" test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb94cf0-af5c-4229-84e5-e987a0d93429",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, balanced_accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "train_f1s=[]\n",
    "meanScores =[]\n",
    "range= []\n",
    "# too low max_depth -> no result\n",
    "for max_depth in np.arange(8,21,1):\n",
    "    print('max_depth',max_depth)\n",
    "    # Instantiate model and k-fold\n",
    "    modelClf = RandomForestClassifier(random_state=42, max_depth=max_depth)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = cross_val_score(modelClf, x_train, y_train,verbose=1, scoring=\"f1\", cv=kf)\n",
    "\n",
    "    modelClf.fit(x_train, y_train)\n",
    "    train_preds = modelClf.predict(x_train)\n",
    "    train_f1 = f1_score(y_train,train_preds)\n",
    "    #fd.show_confusion_matrix(y_train, train_preds)\n",
    "    print(\"Cross-validated scores:\", scores)\n",
    "    print(\"Mean f1:\", np.mean(scores))\n",
    "    print(\"train_f1\", train_f1)\n",
    "    print(\"dif\", train_f1-np.mean(scores))\n",
    "    train_f1s.append(train_f1)\n",
    "    meanScores.append(np.mean(scores))\n",
    "    range.append(max_depth)\n",
    "    print('-----------------------')\n",
    "\n",
    "fd.plt_train_test(range, train_f1s, \"train\", meanScores,\" score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984037f3-d4e8-45e5-8205-425d992fb4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import recall_score, precision_score, accuracy_score, balanced_accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "# too low max_depth -> no result\n",
    "train_f1s=[]\n",
    "meanScores =[]\n",
    "range =[]\n",
    "for n_estimators in np.arange(50,301,25):\n",
    "    print('n_estimators',n_estimators)\n",
    "    # Instantiate model and k-fold\n",
    "    modelClf = RandomForestClassifier(random_state=42, max_depth=15, n_estimators=n_estimators)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    scores = cross_val_score(modelClf, x_train, y_train,verbose=1, scoring=\"f1\", cv=kf)\n",
    "\n",
    "    modelClf.fit(x_train, y_train)\n",
    "    train_preds = modelClf.predict(x_train)\n",
    "    train_f1 = f1_score(y_train,train_preds)\n",
    "    #fd.show_confusion_matrix(y_train, train_preds)\n",
    "    print(\"Cross-validated scores:\", scores)\n",
    "    print(\"Mean f1:\", np.mean(scores))\n",
    "    print(\"train_f1\", train_f1)\n",
    "    print(\"dif\", train_f1-np.mean(scores))\n",
    "    train_f1s.append(train_f1)\n",
    "    meanScores.append(np.mean(scores))\n",
    "    range.append(n_estimators)\n",
    "    print('-----------------------')\n",
    "\n",
    "fd.plt_train_test(range, train_f1s, \"train\", meanScores,\" score\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f062974-4865-4a10-964e-7cfa0e8203bc",
   "metadata": {},
   "source": [
    "# Scaling choice\n",
    "with random forest the scaling has no influence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79818645-df0a-44ed-91cd-68b87bca2cde",
   "metadata": {},
   "source": [
    "# Hyperparameters tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921039dc-bfb5-4eab-b9c1-885d5605fa55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "from scipy.stats import randint\n",
    "\n",
    "modelClf = RandomForestClassifier(random_state=42)\n",
    "dic_param={\n",
    "    'n_estimators': randint(40,110),\n",
    "    'max_depth': randint(10,25)\n",
    "}\n",
    "res=fd.hyperparameterSelectionRandomizedSearchCV(modelClf, dic_param, 'f1', dfTrx, predictors, [], None)\n",
    "print(res)\n",
    "\n",
    "#[CV 5/5; 10/10] END max_depth=20, n_estimators=106;, score=0.121 total time= 2.8min\n",
    "#{'max_depth': 22, 'n_estimators': 60}\n",
    "#0.16552081045379466\n",
    "#score   0.8500551267916208\n",
    "#scoref1 0.8500551267916208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b0cba8-6444-4c91-a313-66c1d4e7e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script false\n",
    "\n",
    "\n",
    "modelClf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "dic_param={\n",
    "    'n_estimators':[55,60,65],\n",
    "    'max_depth':[21,22,23,24]\n",
    "}\n",
    "res=fd.hyperparameterSelectionGridSearchCV(modelClf, dic_param, 'f1', dfTrx, predictors, [], None)\n",
    "print(res)\n",
    "\n",
    "#{'max_depth': 23, 'n_estimators': 60}\n",
    "#0.1914795461010364\n",
    "#scoref1 0.8729042725797729"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ae1be4-a998-4ad9-8cd0-131e5ce3af52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "then= datetime.now()\n",
    "predictors = fd.getPredictors(dfTrx)\n",
    "\n",
    "x_train, x_test, y_train, y_test, scaler =fd.split_data(dfTrx,predictors)\n",
    "\n",
    "modelClf = RandomForestClassifier(random_state=42)\n",
    "parameters={'max_depth': max_depthFound, 'n_estimators':n_estimatorsFound}\n",
    "modelClf.set_params(**parameters)\n",
    "\n",
    "modelClf.fit(x_train, y_train)\n",
    "predsTrain = modelClf.predict(x_train)\n",
    "predsTest = modelClf.predict(x_test)\n",
    "\n",
    "now = datetime.now()\n",
    "duration= now - then\n",
    "duration_in_s = duration.total_seconds()\n",
    "print(\"Duration \",duration_in_s)\n",
    "resultMd.update_time_response_result('07-sklearn.ensemble.a-bagging','RandomForest','2-After tuning', duration_in_s)\n",
    "f1,mcc,roc=fd.print_scores(y_test, predsTest,'all')\n",
    "resultMd.update_performance_test_result('07-sklearn.ensemble.a-bagging','RandomForest','2-After tuning', f1,mcc,roc)\n",
    "\n",
    "fd.print_scores(y_train, predsTrain,'f1', False)\n",
    "fd.print_scores(y_test, predsTest,'f1')\n",
    "fd.show_importance(modelClf, predictors)\n",
    "fd.show_confusion_matrix(y_test, predsTest)\n",
    "fd.show_prediction_graph(modelClf, x_test,y_test,'../imgs/FD07A-RandomForestClassifierProbaHistogram' if saveImage else None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8d9491-f833-4537-9a65-076404bde78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = fd.getAllFiles()\n",
    "\n",
    "range = []\n",
    "f1s = []\n",
    "rocs = []\n",
    "loop =0\n",
    "for file in files:\n",
    "    loop=loop+1\n",
    "    range.append(loop)\n",
    "    print(file)\n",
    "  \n",
    "    dfTrx = pd.read_csv('../data/cleaned/'+source+file)\n",
    "    predictors = fd.getPredictors(dfTrx)\n",
    "\n",
    "    preds = modelClf.predict(dfTrx[predictors])\n",
    "\n",
    "    f1,mcc,roc= fd.print_scores(dfTrx['Class'], preds,'All', True)\n",
    "    #fd.show_importance(modelClf,predictors)\n",
    "    fd.show_confusion_matrix(dfTrx['Class'], preds)\n",
    "    f1s.append(f1)\n",
    "    rocs.append(roc)\n",
    "\n",
    "fd.plt_train_test(range, f1s)\n",
    "resultMd.update_performance_nextdays_result('07-sklearn.ensemble.a-bagging','RandomForestClassifier','2-After tuning', f1s[0],f1s[1],f1s[2],f1s[3],rocs[0],rocs[1],rocs[2],rocs[3])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e067771-f278-4280-96ab-15c06dc89bc7",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
